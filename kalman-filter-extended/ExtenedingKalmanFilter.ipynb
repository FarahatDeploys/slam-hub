{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92965c00",
   "metadata": {},
   "source": [
    "# Extended Kalman Filter\n",
    "\n",
    "\n",
    "The motivation for this lecture is to resolve a limitation that kalman filter hits, which is the lienarity assumption.\n",
    "\n",
    "kalman approach mandates that the transition probability must be governed by a linear process, this is a huge limitation for some applications including robotics.\n",
    "\n",
    "Before we delve into the solution we do a quick recap.\n",
    "\n",
    "### quick problem recap \n",
    "\n",
    "given what we know about the robot including \n",
    "- robot controls \n",
    "$$u_{1:T} = {u_{1},u_{2},u_{3},...u_{t}}$$\n",
    "- robot observations \n",
    "$$z_{1:T} = {z_{1},z_{2},z_{3},...z_{t}}$$\n",
    "\n",
    "we would like to estimate what we don't know : \n",
    "-   m (map of the enviroment)\n",
    "- location of the robot \n",
    "$$ x_{0:T} = {x_1, x_2,x_3,.....x_T} $$\n",
    "\n",
    "\n",
    "\n",
    "Bayes framework is generally relying on two steps (predication and update), the kalman filter is challenged in the prediction and update step if these process are not subjected to guassian uncertantiy.\n",
    "\n",
    "## Extending kalman\n",
    "\n",
    "kalman filter worked perfectly when the process model used to be linear:\n",
    "\n",
    "$$x_{t} = A x_{t-1} + B u_{t-1}$$\n",
    "\n",
    "A problem arises as we propose a nonlinear function g, so that\n",
    "$$x_{t} = g(x_{t-1} , u_{t-1})$$\n",
    "\n",
    "one solution to extended kalman is by using the taylor series, the process is called local linearization.\n",
    "\n",
    "This local lineraization is applied around point (t-1)\n",
    "\n",
    "\n",
    "so that the non linear equation can be reduced to a line equation around the mean ($\\mu_{t-1}$) as follows:\n",
    "\n",
    "\n",
    "$$g(u_t,x_{t-1}) \\approx  g(u_t,\\mu_{t-1}) + \\frac{\\partial g(u_t,\\mu_{t-1})}{\\partial x_{t-1}} (x_{t-1}-\\mu_{t-1})$$\n",
    "\n",
    "in other words the nonlinear function = constant (value around mean) + slope * how far we are from this local point \n",
    "\n",
    "This slope or derivative is what we call a jacobian.\n",
    "\n",
    "\n",
    "### Implementing the jacobians into bayes framwork part (TBD)\n",
    "\n",
    "## Extended Kalman Algorithm ! \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\textbf{1. Prediction (Motion)} & \\\\\n",
    "\\bar{\\mu}_t &= g(u_t, \\mu_{t-1}) && \\text{// Predict State (Non-linear)} \\\\\n",
    "\\bar{\\Sigma}_t &= G_t \\Sigma_{t-1} G_t^T + Q_t && \\text{// Predict Covariance} \\\\[1em]\n",
    "\n",
    "\\textbf{2. Correction (Measurement)} & \\\\\n",
    "y_t &= z_t - h(\\bar{\\mu}_t) && \\text{// Innovation (Surprise)} \\\\\n",
    "S_t &= H_t \\bar{\\Sigma}_t H_t^T + R_t && \\text{// Innovation Covariance} \\\\\n",
    "K_t &= \\bar{\\Sigma}_t H_t^T S_t^{-1} && \\text{// Kalman Gain} \\\\\n",
    "\\mu_t &= \\bar{\\mu}_t + K_t y_t && \\text{// Update State} \\\\\n",
    "\\Sigma_t &= (I - K_t H_t) \\bar{\\Sigma}_t && \\text{// Update Covariance}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24dba85",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
