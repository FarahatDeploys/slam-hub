{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633f6b0d-6a52-4eda-a2ef-7b160be43c33",
   "metadata": {},
   "source": [
    "# 1. Prerequisites: Bayes' Rule & Notation\n",
    "\n",
    "## Standard Bayes' Rule\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(B \\mid A)\\,P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "## Bayes' Rule with Background Knowledge (Context)\n",
    "In robotics, we always have past context $C$. Bayes' rule with context adds $C$ to all terms:\n",
    "$$\n",
    "P(A \\mid B, C) = \\frac{P(B \\mid A, C)\\,P(A \\mid C)}{P(B \\mid C)}\n",
    "$$\n",
    "\n",
    "## Sequence Notation\n",
    "We use colon notation to represent a sequence:\n",
    "$$\n",
    "z_{1:t} = \\{z_1, z_2, \\ldots, z_t\\}\n",
    "$$\n",
    "\n",
    "Joint intersection:\n",
    "$$\n",
    "P(z_1 \\cap z_2 \\cap \\cdots \\cap z_t \\mid A) = P(z_{1:t} \\mid A)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 2. The Goal: Recursive Bayes Filter\n",
    "\n",
    "We want to represent the belief distribution of the state $x_t$ recursively, without showing a explicit solution:\n",
    "\n",
    "$$\n",
    "\\text{bel}(x_t) = f(\\text{bel}(x_{t-1}),\\; z_t,\\; u_t)\n",
    "$$\n",
    "\n",
    "Definition of belief:\n",
    "$$\n",
    "\\text{bel}(x_t) = p(x_t \\mid z_{1:t}, u_{1:t})\n",
    "$$\n",
    "\n",
    "Split the measurement history:\n",
    "$$\n",
    "\\text{bel}(x_t) = p(x_t \\mid z_t, z_{1:t-1}, u_{1:t})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Applying Bayes' Rule\n",
    "\n",
    "Let:\n",
    "\n",
    "- $A = x_t$  \n",
    "- $B = z_t$  \n",
    "- $C = \\{z_{1:t-1}, u_{1:t}\\}$\n",
    "\n",
    "Applying Bayes:\n",
    "$$\n",
    "p(x_t \\mid z_t, z_{1:t-1}, u_{1:t})\n",
    "=\n",
    "\\frac{\n",
    "p(z_t \\mid x_t, z_{1:t-1}, u_{1:t}) \\;\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t})\n",
    "}{\n",
    "p(z_t \\mid z_{1:t-1}, u_{1:t})\n",
    "}\n",
    "$$\n",
    "\n",
    "## Normalizer (η)\n",
    "\n",
    "The denominator does not depend on $x_t$. Replace with a constant:\n",
    "\n",
    "$$\n",
    "\\eta = \\frac{1}{p(z_t \\mid z_{1:t-1}, u_{1:t})}\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "\\text{bel}(x_t)\n",
    "=\n",
    "\\eta \\;\n",
    "p(z_t \\mid x_t, z_{1:t-1}, u_{1:t})\n",
    "\\;\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t})\n",
    "$$\n",
    "\n",
    "---\n",
    "# 4. The Markov Assumption\n",
    "\n",
    "Under the **Markov Assumption**, the sensor measurement at time $t$ depends **only** on the current state $x_t$, not on any past measurements or controls:\n",
    "\n",
    "$$\n",
    "p(z_t \\mid x_t, z_{1:t-1}, u_{1:t}) \\approx p(z_t \\mid x_t)\n",
    "$$\n",
    "\n",
    "Substituting this into the Bayes update equation:\n",
    "\n",
    "$$\n",
    "\\text{bel}(x_t)\n",
    "=\n",
    "\\eta \\;\n",
    "p(z_t \\mid x_t)\n",
    "\\;\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t})\n",
    "$$\n",
    "\n",
    "This can be written as:\n",
    "\n",
    "$$\n",
    "\\text{bel}(x_t) = \\eta \\;\n",
    "\\underbrace{p(z_t \\mid x_t)}_{\\text{Measurement Model}}\n",
    "\\;\n",
    "\\underbrace{p(x_t \\mid z_{1:t-1}, u_{1:t})}_{\\text{Prediction (Prior)}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "We now focus on the *Prediction (Prior)* term:\n",
    "\n",
    "$$\n",
    "\\underbrace{p(x_t \\mid z_{1:t-1}, u_{1:t})}_{\\text{Prediction (Prior)}}\n",
    "$$\n",
    "\n",
    "### Why this term is difficult\n",
    "\n",
    "This term tries to answer:\n",
    "\n",
    "**“Where am I now, given all past measurements and controls?”**\n",
    "\n",
    "But the robot’s state does not appear out of nowhere.  \n",
    "To reach the current state $x_t$, the robot must have come from **some** previous state $x_{t-1}$.\n",
    "\n",
    "### How to handle it\n",
    "\n",
    "We use the **Law of Total Probability** and sum (integrate) over every possible previous state:\n",
    "\n",
    "$$\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t})\n",
    "=\n",
    "\\int\n",
    "\\underbrace{p(x_t \\mid x_{t-1}, z_{1:t-1}, u_{1:t})}_{\\text{Transition Probability}}\n",
    "\\;\n",
    "\\underbrace{p(x_{t-1} \\mid z_{1:t-1}, u_{1:t})}_{\\text{Previous Belief}}\n",
    "\\; dx_{t-1}\n",
    "$$\n",
    "\n",
    "In words:\n",
    "\n",
    "- The **transition model** tells us how likely it is to move from $x_{t-1}$ to $x_t$ given controls.  \n",
    "- The **previous belief** tells us how likely the robot was at $x_{t-1}$ before receiving the new measurement.\n",
    "\n",
    "Together, they form the prediction step of the Bayes Filter.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86d2df-c081-402c-a311-0d2873697ca7",
   "metadata": {},
   "source": [
    "## What we can notice so far on the Bayes Framework / Bayes Filter \n",
    "it is a recursive state estimation technique\n",
    "different implementations for the exact solution of this recursive techniuqes based on the data proprties\n",
    "- Linear Vs Non Linear Motion models will influence how we implement it-\n",
    "- Gaussains Vs Non Guassians will also affect the implemntation\n",
    "- Parametric Vs Non Parametric\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3beeb0-fedd-421a-89dd-23a90a2753d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
