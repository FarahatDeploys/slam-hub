{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633f6b0d-6a52-4eda-a2ef-7b160be43c33",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The goal of this notebook is to derive the **recursive Bayes Filter**, which allows a robot to **estimate its state over time** given:\n",
    "\n",
    "- control inputs $u_{1:t}$ (e.g., wheel commands)  \n",
    "- sensor measurements $z_{1:t}$ (e.g., LiDAR, camera)\n",
    "\n",
    "We aim to:\n",
    "\n",
    "1. Represent the robot's belief recursively $\\mathrm{bel}(x_t) = fn(bel(x_{t-1}),u_{1:t},z_{1:t})$.  \n",
    "2. Split the update into **prediction** and **measurement update** steps.  \n",
    "\n",
    "\n",
    "   \n",
    "---\n",
    "\n",
    "# 1. Prerequisites: Bayes' Rule and Notation\n",
    "\n",
    "## Bayes' Rule\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(B \\mid A)\\,P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "## Bayes' Rule with Context  \n",
    "In robotics, past information is treated as context \\(C\\):\n",
    "$$\n",
    "P(A \\mid B, C)\n",
    "= \\frac{P(B \\mid A, C)\\,P(A \\mid C)}{P(B \\mid C)}\n",
    "$$\n",
    "\n",
    "## Sequence Notation\n",
    "A sequence is written compactly as:\n",
    "$$\n",
    "z_{1:t} = \\{z_1, z_2, \\ldots, z_t\\}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Goal: The Recursive Bayes Filter\n",
    "\n",
    "Belief is defined as:\n",
    "$$\n",
    "\\text{bel}(x_t) = p(x_t \\mid z_{1:t}, u_{1:t})\n",
    "$$\n",
    "\n",
    "Since we aim to describe the belief over time using it's previous beliefs, it might be a good idea to split the probability based on time step (t) and time step (t-1)\n",
    "\n",
    "$$\n",
    "p(x_t \\mid z_{1:t}, u_{1:t})\n",
    "= p(x_t \\mid z_t, z_{1:t-1}, u_{1:t})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Applying Bayes' Rule\n",
    "\n",
    "Let  \n",
    "- \\(A = x_t\\)  \n",
    "- \\(B = z_t\\)  \n",
    "- \\(C = \\{z_{1:t-1}, u_{1:t}\\}\\)\n",
    "\n",
    "Applying Bayes:\n",
    "$$\n",
    "p(x_t \\mid z_t, z_{1:t-1}, u_{1:t})\n",
    "=\n",
    "\\frac{\n",
    "p(z_t \\mid x_t, z_{1:t-1}, u_{1:t})\n",
    "\\;\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t})\n",
    "}{\n",
    "p(z_t \\mid z_{1:t-1}, u_{1:t})\n",
    "}\n",
    "$$\n",
    "\n",
    "### Normalizer\n",
    "$$\n",
    "\\eta = \\frac{1}{p(z_t \\mid z_{1:t-1}, u_{1:t})}\n",
    "$$\n",
    "\n",
    "So:\n",
    "$$\n",
    "\\text{bel}(x_t)\n",
    "=\n",
    "\\eta \\;\n",
    "p(z_t \\mid x_t, z_{1:t-1}, u_{1:t})\n",
    "\\;\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 4. The Markov Assumption\n",
    "\n",
    "Sensors depend only on the current state:\n",
    "$$\n",
    "p(z_t \\mid x_t, z_{1:t-1}, u_{1:t})\n",
    "\\approx\n",
    "p(z_t \\mid x_t)\n",
    "$$\n",
    "\n",
    "Substitute:\n",
    "$$\n",
    "\\text{bel}(x_t)\n",
    "=\n",
    "\\eta \\;\n",
    "\\underbrace{p(z_t \\mid x_t)}_{\\text{Measurement Model}}\n",
    "\\;\n",
    "\\underbrace{p(x_t \\mid z_{1:t-1}, u_{1:t})}_{\\text{Prediction (Prior)}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Understanding the Prediction Term\n",
    "\n",
    "We approximate:\n",
    "$$\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t})\n",
    "\\approx\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t-1})\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "$$\n",
    "\\text{bel}(x_t)\n",
    "=\n",
    "\\eta \\;\n",
    "p(z_t \\mid x_t)\n",
    "\\;\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t-1})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 6. From Prior at \\(t\\) to Posterior at \\(t-1\\)\n",
    "\n",
    "Using the Law of Total Probability:\n",
    "$$\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t-1})\n",
    "=\n",
    "\\int\n",
    "\\underbrace{p(x_t \\mid x_{t-1}, z_{1:t-1}, u_{1:t-1})}_{\\text{Transition Probability}}\n",
    "\\;\n",
    "\\underbrace{p(x_{t-1} \\mid z_{1:t-1}, u_{1:t-1})}_{\\text{Previous Belief}}\n",
    "\\; dx_{t-1}\n",
    "$$\n",
    "\n",
    "Replace the prior with the belief:\n",
    "$$\n",
    "p(x_t \\mid z_{1:t-1}, u_{1:t-1})\n",
    "=\n",
    "\\int\n",
    "\\underbrace{p(x_t \\mid x_{t-1}, z_{1:t-1}, u_{1:t-1})}_{\\text{Transition Probability}}\n",
    "\\;\n",
    "\\underbrace{\\text{bel}(x_{t-1})}_{\\text{Previous Belief}}\n",
    "\\; dx_{t-1}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 7. Full Recursive Bayes Filter\n",
    "\n",
    "$$\n",
    "\\text{bel}(x_t)\n",
    "=\n",
    "\\eta \\;\n",
    "\\underbrace{p(z_t \\mid x_t)}_{\\text{Measurement Model}}\n",
    "\\int\n",
    "\\underbrace{p(x_t \\mid x_{t-1}, z_{1:t-1}, u_{1:t-1})}_{\\text{Transition Probability}}\n",
    "\\;\n",
    "\\underbrace{\\text{bel}(x_{t-1})}_{\\text{Previous Belief}}\n",
    "\\; dx_{t-1}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "# 8. Simplified Form\n",
    "\n",
    "Since the transition probability does not depend on measurements, but only the previous pose and the control signls:\n",
    "$$\n",
    "p(x_t \\mid x_{t-1}, z_{1:t-1}, u_{1:t-1})\n",
    "\\approx\n",
    "p(x_t \\mid x_{t-1}, u_{t-1})\n",
    "$$\n",
    "\n",
    "Final Bayes Filter equation:\n",
    "$$\n",
    "\\text{bel}(x_t)\n",
    "=\n",
    "\\eta \\;\n",
    "\\underbrace{p(z_t \\mid x_t)}_{\\text{Measurement Model}}\n",
    "\\int\n",
    "\\underbrace{p(x_t \\mid x_{t-1}, u_{t-1})}_{\\text{Transition Probability}}\n",
    "\\;\n",
    "\\underbrace{\\text{bel}(x_{t-1})}_{\\text{Previous Belief}}\n",
    "\\; dx_{t-1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86d2df-c081-402c-a311-0d2873697ca7",
   "metadata": {},
   "source": [
    "## How can we solve this recursive framework ? \n",
    "\n",
    "The Bayes Filter is fundamentally a **recursive state estimation technique**.  \n",
    "Different implementations of this recursive formulation depend on the properties of:\n",
    "\n",
    "- **The transition (motion) model**\n",
    "- **The measurement (sensor) model**\n",
    "\n",
    "Key characteristics that influence the choice of implementation include:\n",
    "\n",
    "- **Linear vs. Non-linear motion models**  \n",
    "- **Gaussian vs. Non-Gaussian noise distributions**  \n",
    "- **Parametric vs. Non-parametric representations**\n",
    "\n",
    "All these characteristics determine how we can practically solve the general Bayes Filter equation while avoding the insane computational complexity of the exact solution.  \n",
    "Different algorithms are adopted based on these properties **(e.g., Kalman Filter, EKF, UKF, Particle Filter)**.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48438693-2763-4126-a582-598f801af6c7",
   "metadata": {},
   "source": [
    "# Motion Models\n",
    "\n",
    "Since that motion models influnce the practical solution of general bayes filter, we will focus first on the motion models, before moving to the different algorithms used to implement bayes framework practically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf75f8b-e5a3-47c9-81cc-6bbf049e0857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
