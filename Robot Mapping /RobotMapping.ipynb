{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9d74ec-6ffe-45ef-b781-3e3c66a63992",
   "metadata": {},
   "source": [
    "## ðŸ“˜ Introduction\n",
    "\n",
    "In this lecture, we begin by defining the term **robot mapping** by breaking it down into its components:\n",
    "\n",
    "- **Robot**: A device or system that moves through an environment.  \n",
    "- **Mapping**: The representation or modeling of that environment, whether feature based representation or grid based represntation.\n",
    "\n",
    "For a robot to successfully navigate, it must perform several key operations. These include **state estimation** for both the map and the robotâ€™s own location (i.e., localization and mapping), followed by **navigation** and **motion planning**.  \n",
    "To understand these concepts, we define the following terms:\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” Key Definitions\n",
    "\n",
    "### **State Estimation**  \n",
    "State estimation is the process of determining the internal state of a system when it cannot be measured directly.  \n",
    "Examples of such states include:  \n",
    "- Position *(x, y, z)*  \n",
    "- Orientation *(yaw, pitch, roll)*  \n",
    "- Velocity  \n",
    "- Acceleration  \n",
    "- Location of landmarks  \n",
    "\n",
    "\n",
    "noise / implicit data -> mathmatical framework and operations -> estimate of variables (State)\n",
    "\n",
    "---\n",
    "\n",
    "### **Localization**  \n",
    "Localization is the process of determining a robotâ€™s position and orientation within a known map.  \n",
    "In other words, localization **is a state estimation process** focused specifically on determining the robotâ€™s location in a known environment.\n",
    "\n",
    "Imagine you are dropped into a room with a blindfold on, but you have a map of the room in your head, since you already visited this room before. \n",
    "We inform you where are you right now for example, you are close to the lamp, By knowing where the lamp is on your mental map, you can start estimating figure out exactly where you are standing right now and where are you as you move forward. \n",
    "\n",
    "However as you move over time you start being more uncertain, not truly sure if you are now very far from the lamp or moderatly far, to eliminate this uncertanity you will need to look around, see the lamp and reduce your uncertanity one more time.\n",
    "\n",
    "\n",
    "This process is called localization, it's made of two steps, predictions and update.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Mapping**  \n",
    "Mapping is the process of constructing a representation of the environment using sensor data collected by the robot.  \n",
    "This is also a form of **state estimation**, but applied to the **environment** itself.\n",
    "\n",
    "\n",
    "Imagine you are walking through a pitch-black room with a flashlight, but you have a magical GPS that tells you your exact coordinates at all times.\n",
    "\n",
    "You shine your flashlight and see a chair. Because you know your location, and you can see how far away the chair is, you can draw that chair on a blank piece of paper. That is Mapping.\n",
    "\n",
    "\n",
    "noisy / Implicit data -> mathmatical operations -> estimation of object locations \n",
    "\n",
    "---\n",
    "\n",
    "### **SLAM â€” Simultaneous Localization and Mapping**  \n",
    "SLAM is the process in which a robot **builds a map of an unknown environment** *while simultaneously* **estimating its own position** within that map.  \n",
    "In SLAM, **localization and mapping happen at the same time**, creating a closed-loop problem that lies at the core of mobile robotics.\n",
    "\n",
    "SLAM is nearly used every where in space-underwater-underground.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Matmatical Formulation of the SLAM Problem**\n",
    "**Given (Inputs)**\n",
    "\n",
    "\n",
    "The control signals of the robot from 1 up to T\n",
    "\n",
    "$$u_{1:T} = \\{u_1, u_2, u_3, \\dots, u_T\\}$$\n",
    "\n",
    "Observations ($z_{1:T}$): The sequence of sensor measurements collected by the robot from the environment (e.g., LiDAR scans, camera images, landmark distances).\n",
    "\n",
    "\n",
    "$$z_{1:T} = \\{z_1, z_2, z_3, \\dots, z_T\\}$$\n",
    "\n",
    "**Wanted (Outputs)**\n",
    "\n",
    "\n",
    "The Map ($m$): A representation of the environment (e.g., feature-based map, grid map).\n",
    "\n",
    "\n",
    "$$m$$\n",
    "\n",
    "The Robot Path ($x_{0:T}$): The sequence of the robot's poses (positions and orientations) from the start to the current time.\n",
    "\n",
    "\n",
    "$$x_{0:T} = \\{x_0, x_1, x_2, \\dots, x_T\\}$$\n",
    "\n",
    "### SLAM Probability Formulation \n",
    "\n",
    "Since we have noisy data, and we are trying to form some estimate of the robot location, we will have to use probability theory as a tool to form this estimate for the location of the robot, and the model of the map.\n",
    "\n",
    "The problem can be representes as follow, we are trying to figure out the probability distribtion of the location and the map.\n",
    "\n",
    "Word distribution can be understood as, **\"I don't know exactly where I am, so Iâ€™m going to calculate how likely I am to be in different spots\"**\n",
    "\n",
    "$$\n",
    "p(x_{0:T}, m \\mid z_{1:T}, u_{1:T})\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x_0 \\cap x_1 \\cap \\dots \\cap x_T \\cap m \\mid z_1 \\cap  z_2 \\cap z_3 \\dots \\cap z_T , u_{1:T})\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\underbrace{p}_{\\text{distribution}}(\\underbrace{x_{0:T}}_{\\text{path}}, \\underbrace{m}_{\\text{map}} \\mid \\underbrace{z_{1:T}}_{\\text{observations}}, \\underbrace{u_{1:T}}_{\\text{controls}})\n",
    "$$\n",
    "\n",
    "\n",
    "### From online SLAM to offline SLAM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d45b1-6d35-4258-9e25-6beda157b37f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1b46c-2dda-4523-aeda-4ebb5631b68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
